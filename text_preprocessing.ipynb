{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/6GBcpHXTPFyziXQAkJ4C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azganushpoghosyan/nlp/blob/master/text_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook guides you through the essential steps to convert raw text into a clean, standardized format, essential for various natural language processing tasks."
      ],
      "metadata": {
        "id": "Wa-RgwFjta0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "import pandas as pd  # For working with structured data in a tabular form\n",
        "import numpy as np  # Essential for numerical operations and working with arrays\n",
        "import nltk  # Natural Language Toolkit for NLP tasks\n",
        "import spacy  # An advanced NLP library\n",
        "from nltk.stem import WordNetLemmatizer  # Lemmatization\n",
        "from textblob import Word, TextBlob  # TextBlob for text processing\n",
        "from nltk.corpus import stopwords  # Stopwords for filtering common words\n",
        "from nltk.stem import PorterStemmer  # Stemming\n",
        "import warnings  # For handling warnings\n",
        "warnings.filterwarnings('ignore')  # Ignore warnings to improve readability\n",
        "import re  # Regular expressions for text pattern matching and manipulation"
      ],
      "metadata": {
        "id": "5aBTyRtpt5Q3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "nltk.download('vader_lexicon', quiet=True)"
      ],
      "metadata": {
        "id": "Y6LN8wV6R7cV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "651417b8-66df-454c-80fb-3b21c9fadb22"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame with a column named 'original_text' and populate it with the sample text\n",
        "sample_text = 'Overview:\\nThe PBNA Insights Reporting Analyst’s role will work primarily with Sparkling team where his/her role will be focused on enhancing and automating business reporting to fuel stronger, faster business performance insight for the PBNA Marketing and Insights teams. This includes connecting multiple data sources through curated metrics and developing calculated metrics to focus on the key outcome and diagnostic measures. A critical element of this role is to be able to deliver the strategic presentation focused around future Growth for PepsiCo.\\nResponsibilities:\\nExecute against team charter for Reporting vertical within SSC\\no Execute market, portfolio, and brand level reporting of marketing KPI performance (utilizing dashboards, templated decks, and reporting tools)\\no Leverage business performance explanations from teams around the world to incorporate considerations beyond data into reporting\\no Explain business performance, drivers, and optimization opportunities\\no Monitor key channel, customer, competitor (incl. PL) and emerging player performance and execute reporting at required intervals\\no Deliver against needs of stakeholders, requestors and sector/functional leaders\\no Support processes for output adherence and delivery to agreed scope – in line with the agreed timelines, aligned templates and content management\\no Monitor and act upon regular feedback inputs from deliverables end-users and Business Partners\\no Flag and monitor any business risks related to delivering the operational output (facilities, IT resources, recruitment efforts)\\no Primary executor responsible for flawless support process and structure, including knowledge management and transfer\\no Support communication processes with Reporting vertical leaders and Business Partners (project planning, workflow monitoring, quality checks, on-going changes)\\no Help Reporting vertical leadership develop and finetune internal COE processes (work-flow mapping, pain-points and bottlenecks management) both related to service delivery and internal center operations\\no Improve existing processes based on frequent end-user and Business Partner feedback loop Qualifications:'\n",
        "df = pd.DataFrame({'original_text': [sample_text]})"
      ],
      "metadata": {
        "id": "j9LxYzjA-Nuw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Preprocessing steps\n",
        "\n",
        "*   Standardize text: Convert all characters in the text to lowercase. This ensures uniformity in the text representation, making it easier for subsequent analysis.\n",
        "\n",
        "*   Remove punctuation: Eliminate punctuation marks from the text. This step helps focus on the actual words and improves the consistency of tokenization.\n",
        "\n",
        "*   Remove numbers: Exclude numerical digits from the text. Removing numbers can be beneficial in tasks where numeric values are not essential for analysis, such as text classification or sentiment analysis.\n",
        "\n",
        "*   Remove english stopwords: Filter out common English stopwords (e.g., \"the,\" \"and,\" \"is\") that typically do not contribute much meaning to the text. Removing stopwords reduces noise in the data.\n",
        "\n",
        "*   Create tokens from words: Tokenization involves breaking down the text into individual words or tokens. This step is fundamental for further analysis, as it transforms the text into a format suitable for natural language processing tasks.\n",
        "\n",
        "*   Stem the tokens: Apply stemming to reduce words to their base or root form by removing suffixes. Stemming helps in capturing the core meaning of words and reducing variations.\n",
        "\n",
        "*   Lemmatize the tokens: Lemmatization is another technique for reducing words to their base or dictionary form (lemma). Unlike stemming, lemmatization considers the context and meaning of words, providing a more accurate representation.\n",
        "\n"
      ],
      "metadata": {
        "id": "qPgyCeOKX3ev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_preprocessing(text, result = 'clean_tokens'):\n",
        "    \"\"\"\n",
        "    Preprocesses the raw text applying the following steps: standardize, remove numbers, punctuation and stopwords, stem and lemmatize the words.\n",
        "\n",
        "    Parameters:\n",
        "    - text (str): The raw text to be preprocessed.\n",
        "    - result (str): The step to include in the output. Possible values: 'standardized_text', 'no_punctuation', 'no_numbers', 'no_stopwords', 'stemmed_tokens', 'lemmatized_tokens', 'clean_tokens'. Default is 'clean_tokens'.\n",
        "\n",
        "    Returns:\n",
        "    - str or list: The result of the specified step applied.\n",
        "    \"\"\"\n",
        "    text = str(text)\n",
        "    # remove newline characters\n",
        "    combined_text = text.replace('\\n', ' ')\n",
        "\n",
        "    # standardization of letters (make lowercase)\n",
        "    standardized_text = combined_text.lower()\n",
        "    if result == 'standardized_text':\n",
        "      return standardized_text\n",
        "\n",
        "    # remove punctuation\n",
        "    no_punctuation = re.sub(r'[^\\w\\s]', '', standardized_text)\n",
        "    if result == 'no_punctuation':\n",
        "      return no_punctuation\n",
        "\n",
        "    # remove numbers\n",
        "    no_numbers = re.sub(r'\\d', '', no_punctuation)\n",
        "    if result == 'no_numbers':\n",
        "      return no_numbers\n",
        "\n",
        "    # remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    no_stopwords = \" \".join([word for word in no_numbers.split() if word not in stop_words])\n",
        "    if result == 'no_stopwords':\n",
        "      return no_stopwords\n",
        "\n",
        "    # spacy tokenization\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "    doc_tokenize = nlp(no_stopwords)\n",
        "    tokens = [token.text for token in doc_tokenize]\n",
        "    if result == 'tokens':\n",
        "      return tokens\n",
        "\n",
        "    # stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
        "    if result == 'stemmed_tokens':\n",
        "      return stemmed_tokens\n",
        "\n",
        "    # lemmatization\n",
        "    sentence = \" \".join(tokens)\n",
        "    doc_lemmitize = nlp(sentence)\n",
        "    lemmatized_tokens = [token.lemma_ for token in doc_lemmitize]\n",
        "    if result == 'lemmatized_tokens':\n",
        "      return lemmatized_tokens\n",
        "\n",
        "    # final cleaning: remove empty strings, single letters and duplicates\n",
        "    clean_tokens = [token for token in list(set(lemmatized_tokens)) if token.strip() != '' and len(token) > 1]\n",
        "    if result == 'clean_tokens':\n",
        "      return clean_tokens"
      ],
      "metadata": {
        "id": "bN9wiH04xya5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply preprocessing function to the sample data\n",
        "standardized_text = text_preprocessing(sample_text, 'standardized_text')\n",
        "no_punctuation = text_preprocessing(sample_text, 'no_punctuation')\n",
        "no_numbers = text_preprocessing(sample_text, 'no_numbers')\n",
        "no_stopwords = text_preprocessing(sample_text, 'no_stopwords')\n",
        "stemmed_tokens = text_preprocessing(sample_text, 'stemmed_tokens')\n",
        "lemmatized_tokens = text_preprocessing(sample_text, 'lemmatized_tokens')\n",
        "clean_tokens = text_preprocessing(sample_text, 'clean_tokens')"
      ],
      "metadata": {
        "id": "goL1ZeSs4LJy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the result of each step as a separate column in the dataframe\n",
        "df['standardized_text'] = [standardized_text]\n",
        "df['no_punctuation'] = [no_punctuation]\n",
        "df['no_numbers'] = [no_numbers]\n",
        "df['no_stopwords'] = [no_stopwords]\n",
        "df['stemmed_tokens'] = [\" \".join(stemmed_tokens)]\n",
        "df['lemmatized_tokens'] = [\" \".join(lemmatized_tokens)]\n",
        "df['clean_tokens'] = [\" \".join(clean_tokens)]\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "H4ALEk7m_JEW",
        "outputId": "3f53d1d1-11cf-4d6b-c832-aa64a10389ca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       original_text  \\\n",
              "0  Overview:\\nThe PBNA Insights Reporting Analyst...   \n",
              "\n",
              "                                   standardized_text  \\\n",
              "0  overview: the pbna insights reporting analyst’...   \n",
              "\n",
              "                                      no_punctuation  \\\n",
              "0  overview the pbna insights reporting analysts ...   \n",
              "\n",
              "                                          no_numbers  \\\n",
              "0  overview the pbna insights reporting analysts ...   \n",
              "\n",
              "                                        no_stopwords  \\\n",
              "0  overview pbna insights reporting analysts role...   \n",
              "\n",
              "                                      stemmed_tokens  \\\n",
              "0  overview pbna insight report analyst role work...   \n",
              "\n",
              "                                   lemmatized_tokens  \\\n",
              "0  overview pbna insight report analyst role work...   \n",
              "\n",
              "                                        clean_tokens  \n",
              "0  utilize incl charter support customer focus au...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-29744475-2d43-426e-aeff-08b6fa51e49f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_text</th>\n",
              "      <th>standardized_text</th>\n",
              "      <th>no_punctuation</th>\n",
              "      <th>no_numbers</th>\n",
              "      <th>no_stopwords</th>\n",
              "      <th>stemmed_tokens</th>\n",
              "      <th>lemmatized_tokens</th>\n",
              "      <th>clean_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Overview:\\nThe PBNA Insights Reporting Analyst...</td>\n",
              "      <td>overview: the pbna insights reporting analyst’...</td>\n",
              "      <td>overview the pbna insights reporting analysts ...</td>\n",
              "      <td>overview the pbna insights reporting analysts ...</td>\n",
              "      <td>overview pbna insights reporting analysts role...</td>\n",
              "      <td>overview pbna insight report analyst role work...</td>\n",
              "      <td>overview pbna insight report analyst role work...</td>\n",
              "      <td>utilize incl charter support customer focus au...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29744475-2d43-426e-aeff-08b6fa51e49f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-29744475-2d43-426e-aeff-08b6fa51e49f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-29744475-2d43-426e-aeff-08b6fa51e49f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}